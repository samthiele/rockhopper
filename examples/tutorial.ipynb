{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rockhopper\n",
    "from rockhopper import loadPLY, exportZA\n",
    "from rockhopper import testServer\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/thiele67/Documents/Python/rock-hopper/rockhopper/ui\n",
      " * Serving Flask app 'rockhopper.server'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:3003\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:03] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:08] \"GET /index.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:08] \"GET /static/js/main.6f1f380c.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:08] \"GET /static/css/main.1d43fd09.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:08] \"GET /manifest.json HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:08] \"GET /hopper_128.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [15/Mar/2025 12:40:08] \"GET /hopper_256.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "testServer(os.path.abspath('../sandbox/test.zarr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data\n",
    "\n",
    "Lets load an example point cloud. `rockhopper` natively supports PLY format point clouds, which can easily be created/converted using e.g., [CloudCompare](https://www.danielgm.net/cc/).  \n",
    "\n",
    "In the following we load an example point cloud (you will probably need to change the path) and extract the point coordinates, colours, normals and scalar attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15570729 points containing 1 attributes (['scalar_Illuminance_(PCV)'])\n"
     ]
    }
   ],
   "source": [
    "# load data from a PLY file\n",
    "cloud = loadPLY('../sandbox/testcloud.ply')\n",
    "\n",
    "# retrieve attributes from resulting dict\n",
    "xyz = cloud['xyz']\n",
    "rgb = cloud['rgb']\n",
    "normals = cloud['normals']\n",
    "attr = cloud['attr']\n",
    "attr_names =  cloud['names']\n",
    "\n",
    "print(\"Loaded %d points containing %d attributes (%s)\"%(len(xyz), len(attr_names), attr_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing for Zarr\n",
    "\n",
    "Point data is served to our virtual field trip as a chunked array, using a compression and streaming tool called [zarr](https://zarr.readthedocs.io/en/stable/). \n",
    "\n",
    "To prepare for this, we need to concatenate our attributes into a single (n,d) array. This will contain all our (n) point coordinates, colours and attributes (d). At a minimum, coordinates and colours must be defined (d=6), but additional bands or properties can be included too (d > 6).\n",
    "\n",
    "In the following we do this such that for each point we have `x,y,z,r,g,b,i`, where `i` is the scalar field we loaded from our point cloud (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15570729, 7)\n"
     ]
    }
   ],
   "source": [
    "# combine into a single array layout for exporting\n",
    "xyzrgbattr = np.hstack([xyz, rgb, attr])\n",
    "print(xyzrgbattr.shape) # everything is concatenated now into a flat array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define which visualisation options we want available for this point cloud in our virtual field trip. We do this by creating a `style` dictionary that lets us define different true- and false-colour composites to view, and also define a colour-ramp for scalar attribute(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmn = np.percentile( xyz-np.mean(xyz,axis=0)[None,:], 2, axis=0) # value used as black for our false colour mapping\n",
    "vmx = np.percentile( xyz-np.mean(xyz,axis=0)[None,:], 98, axis=0) # value used as white for our false colour mapping\n",
    "stylesheet = { 'rgb':{'R':(3,0,1), # dimensions of our data array to map to \"red\", vmin, vmax\n",
    "                 'G':(4,0,1),'B':(5,0,1)}, # other colors (to give true-colour visualisation) \n",
    "          'xyz':{'R':(0,vmn[0],vmx[0]), # example false colour visualisation\n",
    "                 'G':(1,vmn[1],vmx[1]),'B':(2,vmn[2],vmx[2])} }\n",
    "\n",
    "vmn = np.percentile( xyz[:,2]-np.mean(xyz[:,2]), 2, axis=0) # min value of colour ramp\n",
    "vmx = np.percentile( xyz[:,2]-np.mean(xyz[:,2]), 98, axis=0) # max value of colour ramp\n",
    "stylesheet['elev'] = (2, # index of attribute to colour map\n",
    "                {'scale':'viridis', 'limits':(vmn,vmx,255)}) # colour map properties\n",
    "\n",
    "vmn = np.percentile( attr[:,0], 2, axis=0) # min value of colour ramp\n",
    "vmx = np.percentile( attr[:,0], 98, axis=0) # max value of colour ramp\n",
    "stylesheet['illu'] = (6, {'scale':['#ca0020','#f4a582','#f7f7f7','#92c5de','#0571b0'], # use custom colours!\n",
    "                      'limits':(vmn,vmx,16)} ) # and use e.g., quantile limits instead of equidistant (e) ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rgb': {'R': (3, 0, 1), 'G': (4, 0, 1), 'B': (5, 0, 1)},\n",
       " 'xyz': {'R': (0, -111.18915511475643, 131.60887955321232),\n",
       "  'G': (1, -142.23502484243363, 116.52297076303512),\n",
       "  'B': (2, -49.45066771570964, 38.37037720616536)},\n",
       " 'elev': (2,\n",
       "  {'scale': 'viridis',\n",
       "   'limits': (-49.45066771570964, 38.37037720616536, 255)}),\n",
       " 'illu': (7,\n",
       "  {'scale': ['#ca0020', '#f4a582', '#f7f7f7', '#92c5de', '#0571b0'],\n",
       "   'limits': (0.27542373538017273, 0.7245762944221497, 16)})}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stylesheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to zarr\n",
    "\n",
    "Now we have everything needed to convert our points into zarr format. This is a directory structure that allows the front-end (our web-based virtual fieldtrip viewer) to stream points more efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our new zarr directory here\n",
    "out_path = '../sandbox/test.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiele67/conda/envs/hylite/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1934: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=3)\n",
      "                                         \r"
     ]
    }
   ],
   "source": [
    "exportZA( xyzrgbattr, # our array to export\n",
    "          out_path, # the path to save this [for uploading to a server later]\n",
    "          chunk_size=200000, # number of points in each patch streamed to the viewer\n",
    "          resolution=0.1, # downsample our point cloud to this resolution (important to keep file size low)\n",
    "          stylesheet=stylesheet) # stylesheet defining how our cloud will be visualised\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a test server\n",
    "\n",
    "To test our dataset, we need to launch a local web server that can pass the point data to our web-viewer. For real applications we would upload the datasets to our data storage server (e.g., Google Cloud or Amazon S3), but for testing it is useful to be able to run it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hylite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
